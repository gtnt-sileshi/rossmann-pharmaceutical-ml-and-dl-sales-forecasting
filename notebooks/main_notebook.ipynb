{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing, Model Creation and Optimization\n",
    "## What this notebook does is:\n",
    "\n",
    "- Preprocess the data\n",
    "- Train the model\n",
    "- Save the trained model\n",
    "- Prepare data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\KAIM-Cohort-3\\Week 4\\rossmann-pharmaceutical-ml-and-dl-sales-forecasting\\notebooks\n",
      "c:\\Users\\HP\\Desktop\\KAIM-Cohort-3\\Week 4\\rossmann-pharmaceutical-ml-and-dl-sales-forecasting\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory of the project\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "print(parent_dir)\n",
    "\n",
    "# Insert the path to the parent directory\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# # Insert the path to the Scripts directory\n",
    "# sys.path.insert(0, os.path.join(parent_dir, 'Scripts'))\n",
    "\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom scripts\n",
    "from scripts.data_preprocessing import load_data, preprocess_data, create_lstm_dataset, build_lstm_model\n",
    "from scripts.model_training import train_rf_model, save_rf_model, save_lstm_model, load_lstm_model, train_lstm_model\n",
    "from scripts.utils import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Use DEBUG for detailed logs\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"../logs/model.log\"),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\KAIM-Cohort-3\\Week 4\\rossmann-pharmaceutical-ml-and-dl-sales-forecasting\\scripts\\data_preprocessing.py:21: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame columns: Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
      "       'StateHoliday', 'SchoolHoliday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = load_data('../data/train.csv')\n",
    "    print(\"Loaded DataFrame columns:\", df.columns)  # Debugging aid\n",
    "    X, y = preprocess_data(df)\n",
    "except Exception as e:\n",
    "    log(f\"Error during data loading/preprocessing: {e}\")\n",
    "    raise  # Re-raise the error to inspect it in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
      "       'StateHoliday', 'SchoolHoliday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save the Random Forest model\n",
    "try:\n",
    "    rf_model = train_rf_model(X, y)\n",
    "    save_rf_model(rf_model, '../rf_model.pkl')\n",
    "except Exception as e:\n",
    "    log(f\"Error during Random Forest model training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\KAIM-Cohort-3\\Week 4\\rossmann-pharmaceutical-ml-and-dl-sales-forecasting\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m127152/127152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 2ms/step - loss: 0.2327\n",
      "Epoch 2/5\n",
      "\u001b[1m127152/127152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2ms/step - loss: 0.2125\n",
      "Epoch 3/5\n",
      "\u001b[1m127152/127152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2ms/step - loss: 0.2107\n",
      "Epoch 4/5\n",
      "\u001b[1m127152/127152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2ms/step - loss: 0.2117\n",
      "Epoch 5/5\n",
      "\u001b[1m127152/127152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2ms/step - loss: 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 17:18:14,413 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized LSTM Model Training Loss: 0.21103939414024353\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for LSTM\n",
    "try:\n",
    "    # Reshape X if needed\n",
    "    X_lstm, y_lstm = create_lstm_dataset(X.reshape(-1, 1), time_steps=5)\n",
    "\n",
    "    # Train and save the LSTM model\n",
    "    lstm_model = train_lstm_model(X_lstm, y_lstm)\n",
    "    save_lstm_model(lstm_model, '../lstm_model.h5')\n",
    "except Exception as e:\n",
    "    log(f\"Error during LSTM model training: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the API (run this in a separate terminal or command line)\n",
    "# !python model_serving.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
